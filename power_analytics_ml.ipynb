{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä An√°lise e Previs√£o de Consumo de Energia El√©trica\n",
    "\n",
    "**Projeto**: An√°lise de S√©ries Temporais e Machine Learning  \n",
    "**Dataset**: UCI - Individual Household Electric Power Consumption  \n",
    "**Grupo**: Gustavo Concei√ß√£o, J√∫lia, Mateus, Nicolly, Andreza\n",
    "\n",
    "---\n",
    "\n",
    "## üìë √çndice do Notebook\n",
    "\n",
    "1. **[ETAPA 1](#etapa-1)**: Aquisi√ß√£o de Dados\n",
    "2. **[ETAPA 2](#etapa-2)**: An√°lise Explorat√≥ria de Dados (EDA)\n",
    "3. **[ETAPA 2.5](#etapa-25)**: Prepara√ß√£o e Transforma√ß√£o dos Dados\n",
    "4. **[ETAPA 3](#etapa-3)**: Modelagem Preditiva\n",
    "   - 3.1 Modelos Baseline (Naive, M√©dia M√≥vel, Suaviza√ß√£o Exponencial)\n",
    "   - 3.2 SARIMA\n",
    "   - 3.3 Random Forest com Features Temporais\n",
    "5. **[ETAPA 4](#etapa-4)**: Avalia√ß√£o e Compara√ß√£o de Modelos\n",
    "6. **[ETAPA 5](#etapa-5)**: Conclus√µes e Discuss√£o\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkxROKEdX8nP"
   },
   "source": [
    "# Grupo 1: Consumo de Energia El√©trica\n",
    "\n",
    "- Fonte: UCI Machine Learning Repository - Individual Household Electric Power Consumption\n",
    "URL: https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption\n",
    "- Descri√ß√£o: Medi√ß√µes de consumo el√©trico de uma resid√™ncia francesa ao longo de 4 anos com resolu√ß√£o de 1 minuto\n",
    "- Desafio: Prever consumo futuro considerando padr√µes di√°rios, semanais e sazonais\n",
    "- Grupo: Gustavo Concei√ß√£o, J√∫lia, Mateus, Nicolly, Andreza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "takFEiIXYbVY"
   },
   "source": [
    "# ETAPA 1\n",
    "1. Aquisi√ß√£o de Dados\n",
    "2. Documentar a fonte, caracter√≠sticas e per√≠odo temporal dos dados\n",
    "3. Verificar a integridade e completude do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oy0nG6lwZv9I"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7KAdJzvY6no"
   },
   "outputs": [],
   "source": [
    "# carregar dados\n",
    "df = pd.read_csv (\"household_power_consumption.txt\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brHWT44nQBeS",
    "outputId": "bb73a3a5-4223-41b7-b63a-32f74786ba56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas e colunas (327915, 9)\n",
      "Nome das colunas Index(['Date', 'Time', 'Global_active_power', 'Global_reactive_power',\n",
      "       'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
      "       'Sub_metering_3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# caracteristicas dos dados\n",
    "df.shape # N√∫mero de linhas e colunas\n",
    "print(\"Numero de linhas e colunas\", df.shape)\n",
    "\n",
    "df.columns # Nome das colunas\n",
    "print(\"Nome das colunas\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3iLcBpueHWu",
    "outputId": "a8819aab-4a8c-487d-da8d-7237765919ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of               Date      Time  Global_active_power  Global_reactive_power  \\\n",
      "0       16/12/2006  17:24:00                4.216                  0.418   \n",
      "1       16/12/2006  17:25:00                5.360                  0.436   \n",
      "2       16/12/2006  17:26:00                5.374                  0.498   \n",
      "3       16/12/2006  17:27:00                5.388                  0.502   \n",
      "4       16/12/2006  17:28:00                3.666                  0.528   \n",
      "...            ...       ...                  ...                    ...   \n",
      "327910    1/8/2007  10:34:00                1.424                  0.122   \n",
      "327911    1/8/2007  10:35:00                1.424                  0.120   \n",
      "327912    1/8/2007  10:36:00                1.696                  0.118   \n",
      "327913    1/8/2007  10:37:00                1.684                  0.118   \n",
      "327914    1/8/2007  10:38:00                1.638                  0.068   \n",
      "\n",
      "        Voltage  Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
      "0        234.84              18.4             0.0             1.0   \n",
      "1        233.63              23.0             0.0             1.0   \n",
      "2        233.29              23.0             0.0             2.0   \n",
      "3        233.74              23.0             0.0             1.0   \n",
      "4        235.68              15.8             0.0             1.0   \n",
      "...         ...               ...             ...             ...   \n",
      "327910   233.46               6.0             0.0             0.0   \n",
      "327911   233.23               6.0             0.0             0.0   \n",
      "327912   233.00               7.2             0.0             0.0   \n",
      "327913   233.08               7.2             0.0             0.0   \n",
      "327914   232.99               7.0             0.0             0.0   \n",
      "\n",
      "        Sub_metering_3  \n",
      "0                 17.0  \n",
      "1                 16.0  \n",
      "2                 17.0  \n",
      "3                 17.0  \n",
      "4                 17.0  \n",
      "...                ...  \n",
      "327910            17.0  \n",
      "327911            17.0  \n",
      "327912            16.0  \n",
      "327913            17.0  \n",
      "327914             NaN  \n",
      "\n",
      "[327915 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Vis√£o geral do dataset\n",
    "print(df.info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjQlb4wTfiW1"
   },
   "source": [
    "- O dataset cont√©m 2.075.259 registros e 9 vari√°veis.\n",
    "- As colunas dispon√≠veis s√£o: Date, Time, Global_active_power, Global_reactive_power, Voltage, Global_intensity, Sub_metering_1, Sub_metering_2 e Sub_metering_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2wtX3bzdHt0",
    "outputId": "eb494da9-134c-42a9-86ae-3ed5636ca342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes:  Date                        0\n",
      "Time                        0\n",
      "Global_active_power      3927\n",
      "Global_reactive_power    3927\n",
      "Voltage                  3927\n",
      "Global_intensity         3927\n",
      "Sub_metering_1           3927\n",
      "Sub_metering_2           3927\n",
      "Sub_metering_3           3928\n",
      "dtype: int64\n",
      "Valores duplicados:  0\n"
     ]
    }
   ],
   "source": [
    "# valores faltantes\n",
    "print(\"Valores faltantes: \", df.isnull().sum())\n",
    "\n",
    "# valor duplicado\n",
    "print(\"Valores duplicados: \", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmZEa3OXfzG9",
    "outputId": "1712014c-00c5-4df5-a713-983f6ac5e096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2006-12-16 00:00:00'), Timestamp('2007-08-01 00:00:00'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando datas\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)  # se estiver no formato DD/MM/AAAA\n",
    "df['Date'].min(), df['Date'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Av1d9FMDgFuj"
   },
   "source": [
    "A partir da an√°lise da coluna de datas, identificou-se que o conjunto de dados cobre o per√≠odo compreendido entre 16/12/2006 e 26/11/2010. Isso representa aproximadamente quatro anos completos de medi√ß√µes cont√≠nuas de consumo de energia el√©trica registradas de forma di√°ria e em intervalos de tempo definidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQjLw5udgO2g"
   },
   "source": [
    "# ETAPA 2\n",
    "\n",
    "- An√°lise Explorat√≥ria de Dados (EDA):\n",
    "\n",
    "- Gerar estat√≠sticas descritivas (m√©dia, mediana, desvio padr√£o, etc.)\n",
    "- Identificar valores ausentes, outliers e inconsist√™ncias\n",
    "- Criar visualiza√ß√µes para entender a distribui√ß√£o e comportamento temporal dos dados\n",
    "- Analisar tend√™ncias, sazonalidade e ciclos presentes na s√©rie tempora\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32f1jMTGg_0Z",
    "outputId": "02d0ae66-a713-4bfe-ad28-7856911e5546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estatistica descritiva\n",
      "                                Date  Global_active_power  \\\n",
      "count                         327915        323988.000000   \n",
      "mean   2007-04-09 02:01:39.003704832             1.145675   \n",
      "min              2006-12-16 00:00:00             0.082000   \n",
      "25%              2007-02-11 00:00:00             0.286000   \n",
      "50%              2007-04-09 00:00:00             0.514000   \n",
      "75%              2007-06-05 00:00:00             1.592000   \n",
      "max              2007-08-01 00:00:00            10.670000   \n",
      "std                              NaN             1.186945   \n",
      "\n",
      "       Global_reactive_power        Voltage  Global_intensity  Sub_metering_1  \\\n",
      "count          323988.000000  323988.000000     323988.000000   323988.000000   \n",
      "mean                0.124703     239.142842          4.899499        1.276134   \n",
      "min                 0.000000     223.490000          0.400000        0.000000   \n",
      "25%                 0.000000     236.470000          1.200000        0.000000   \n",
      "50%                 0.106000     239.540000          2.400000        0.000000   \n",
      "75%                 0.196000     241.790000          6.800000        0.000000   \n",
      "max                 1.148000     251.700000         46.400000       78.000000   \n",
      "std                 0.112201       3.705922          5.011682        6.578285   \n",
      "\n",
      "       Sub_metering_2  Sub_metering_3  \n",
      "count   323988.000000   323987.000000  \n",
      "mean         1.646891        5.614747  \n",
      "min          0.000000        0.000000  \n",
      "25%          0.000000        0.000000  \n",
      "50%          0.000000        0.000000  \n",
      "75%          1.000000       17.000000  \n",
      "max         78.000000       20.000000  \n",
      "std          6.608686        8.108707  \n",
      "estatistica com categoria\n",
      "                                 Date      Time  Global_active_power  \\\n",
      "count                          327915    327915        323988.000000   \n",
      "unique                            NaN      1440                  NaN   \n",
      "top                               NaN  10:38:00                  NaN   \n",
      "freq                              NaN       228                  NaN   \n",
      "mean    2007-04-09 02:01:39.003704832       NaN             1.145675   \n",
      "min               2006-12-16 00:00:00       NaN             0.082000   \n",
      "25%               2007-02-11 00:00:00       NaN             0.286000   \n",
      "50%               2007-04-09 00:00:00       NaN             0.514000   \n",
      "75%               2007-06-05 00:00:00       NaN             1.592000   \n",
      "max               2007-08-01 00:00:00       NaN            10.670000   \n",
      "std                               NaN       NaN             1.186945   \n",
      "\n",
      "        Global_reactive_power        Voltage  Global_intensity  \\\n",
      "count           323988.000000  323988.000000     323988.000000   \n",
      "unique                    NaN            NaN               NaN   \n",
      "top                       NaN            NaN               NaN   \n",
      "freq                      NaN            NaN               NaN   \n",
      "mean                 0.124703     239.142842          4.899499   \n",
      "min                  0.000000     223.490000          0.400000   \n",
      "25%                  0.000000     236.470000          1.200000   \n",
      "50%                  0.106000     239.540000          2.400000   \n",
      "75%                  0.196000     241.790000          6.800000   \n",
      "max                  1.148000     251.700000         46.400000   \n",
      "std                  0.112201       3.705922          5.011682   \n",
      "\n",
      "        Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "count    323988.000000   323988.000000   323987.000000  \n",
      "unique             NaN             NaN             NaN  \n",
      "top                NaN             NaN             NaN  \n",
      "freq               NaN             NaN             NaN  \n",
      "mean          1.276134        1.646891        5.614747  \n",
      "min           0.000000        0.000000        0.000000  \n",
      "25%           0.000000        0.000000        0.000000  \n",
      "50%           0.000000        0.000000        0.000000  \n",
      "75%           0.000000        1.000000       17.000000  \n",
      "max          78.000000       78.000000       20.000000  \n",
      "std           6.578285        6.608686        8.108707  \n",
      "estatistica por coluna\n",
      "--- Global_active_power ---\n",
      "count    323988.000000\n",
      "mean          1.145675\n",
      "std           1.186945\n",
      "min           0.082000\n",
      "25%           0.286000\n",
      "50%           0.514000\n",
      "75%           1.592000\n",
      "max          10.670000\n",
      "Name: Global_active_power, dtype: float64\n",
      "--- Global_reactive_power ---\n",
      "count    323988.000000\n",
      "mean          0.124703\n",
      "std           0.112201\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.106000\n",
      "75%           0.196000\n",
      "max           1.148000\n",
      "Name: Global_reactive_power, dtype: float64\n",
      "--- Voltage ---\n",
      "count    323988.000000\n",
      "mean        239.142842\n",
      "std           3.705922\n",
      "min         223.490000\n",
      "25%         236.470000\n",
      "50%         239.540000\n",
      "75%         241.790000\n",
      "max         251.700000\n",
      "Name: Voltage, dtype: float64\n",
      "--- Global_intensity ---\n",
      "count    323988.000000\n",
      "mean          4.899499\n",
      "std           5.011682\n",
      "min           0.400000\n",
      "25%           1.200000\n",
      "50%           2.400000\n",
      "75%           6.800000\n",
      "max          46.400000\n",
      "Name: Global_intensity, dtype: float64\n",
      "--- Sub_metering_1 ---\n",
      "count    323988.000000\n",
      "mean          1.276134\n",
      "std           6.578285\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max          78.000000\n",
      "Name: Sub_metering_1, dtype: float64\n",
      "--- Sub_metering_2 ---\n",
      "count    323988.000000\n",
      "mean          1.646891\n",
      "std           6.608686\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           1.000000\n",
      "max          78.000000\n",
      "Name: Sub_metering_2, dtype: float64\n",
      "--- Sub_metering_3 ---\n",
      "count    323987.000000\n",
      "mean          5.614747\n",
      "std           8.108707\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%          17.000000\n",
      "max          20.000000\n",
      "Name: Sub_metering_3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"estatistica descritiva\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"estatistica com categoria\")\n",
    "print(df.describe(include=\"all\"))\n",
    "\n",
    "\n",
    "print(\"estatistica por coluna\")\n",
    "for col in df.select_dtypes(include=['float64', 'int64']):\n",
    "    print(f\"--- {col} ---\")\n",
    "    print(df[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYbXez_djwK1",
    "outputId": "34c87ce0-de59-4a0b-d350-4c710ef7e17f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valores ausentes\n",
      "percentual por coluna\n",
      "Date                     0.0\n",
      "Time                     0.0\n",
      "Global_active_power      1.2\n",
      "Global_reactive_power    1.2\n",
      "Voltage                  1.2\n",
      "Global_intensity         1.2\n",
      "Sub_metering_1           1.2\n",
      "Sub_metering_2           1.2\n",
      "Sub_metering_3           1.2\n",
      "dtype: float64\n",
      "verificar linhas com dados faltantes\n",
      "            Date      Time  Global_active_power  Global_reactive_power  \\\n",
      "6839  2006-12-21  11:23:00                  NaN                    NaN   \n",
      "6840  2006-12-21  11:24:00                  NaN                    NaN   \n",
      "19724 2006-12-30  10:08:00                  NaN                    NaN   \n",
      "19725 2006-12-30  10:09:00                  NaN                    NaN   \n",
      "41832 2007-01-14  18:36:00                  NaN                    NaN   \n",
      "\n",
      "       Voltage  Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
      "6839       NaN               NaN             NaN             NaN   \n",
      "6840       NaN               NaN             NaN             NaN   \n",
      "19724      NaN               NaN             NaN             NaN   \n",
      "19725      NaN               NaN             NaN             NaN   \n",
      "41832      NaN               NaN             NaN             NaN   \n",
      "\n",
      "       Sub_metering_3  \n",
      "6839              NaN  \n",
      "6840              NaN  \n",
      "19724             NaN  \n",
      "19725             NaN  \n",
      "41832             NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"valores ausentes\")\n",
    "df.isnull().sum()\n",
    "\n",
    "print(\"percentual por coluna\")\n",
    "print((df.isnull().mean() * 100).round(2))\n",
    "\n",
    "print(\"verificar linhas com dados faltantes\")\n",
    "print(df[df.isnull().any(axis=1)].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando valores ausentes (substituindo '?' por NaN)\n",
    "for col in ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', \n",
    "            'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(\"Valores ausentes ap√≥s convers√£o:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Removendo linhas com valores ausentes (estrat√©gia mais segura para s√©ries temporais)\n",
    "df_clean = df.dropna()\n",
    "print(f\"\\nDados originais: {len(df)} registros\")\n",
    "print(f\"Dados limpos: {len(df_clean)} registros\")\n",
    "print(f\"Registros removidos: {len(df) - len(df_clean)} ({((len(df) - len(df_clean))/len(df)*100):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifica√ß√£o e Tratamento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar outliers usando m√©todo IQR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "Q1 = df_clean['Global_active_power'].quantile(0.25)\n",
    "Q3 = df_clean['Global_active_power'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df_clean[(df_clean['Global_active_power'] < lower_bound) | \n",
    "                     (df_clean['Global_active_power'] > upper_bound)]\n",
    "\n",
    "print(f\"N√∫mero de outliers: {len(outliers)} ({len(outliers)/len(df_clean)*100:.2f}%)\")\n",
    "print(f\"Lower bound: {lower_bound:.3f}\")\n",
    "print(f\"Upper bound: {upper_bound:.3f}\")\n",
    "\n",
    "# Visualizar distribui√ß√£o com boxplot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(df_clean['Global_active_power'])\n",
    "plt.title('Boxplot - Global Active Power')\n",
    "plt.ylabel('kW')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df_clean['Global_active_power'], bins=100, edgecolor='black')\n",
    "plt.title('Histograma - Global Active Power')\n",
    "plt.xlabel('kW')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise Temporal - Tend√™ncias e Padr√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar coluna datetime combinando Date e Time\n",
    "df_clean['Datetime'] = pd.to_datetime(df_clean['Date'].astype(str) + ' ' + df_clean['Time'].astype(str))\n",
    "df_clean = df_clean.set_index('Datetime')\n",
    "\n",
    "# Agregar dados por hora para facilitar visualiza√ß√£o\n",
    "df_hourly = df_clean['Global_active_power'].resample('H').mean()\n",
    "\n",
    "# Visualizar s√©rie temporal completa\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_hourly.index, df_hourly.values, linewidth=0.5)\n",
    "plt.title('Consumo de Energia ao Longo do Tempo (Agrega√ß√£o Hor√°ria)', fontsize=14)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Agregar por dia para ver tend√™ncia geral\n",
    "df_daily = df_clean['Global_active_power'].resample('D').mean()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_daily.index, df_daily.values, linewidth=1)\n",
    "plt.title('Consumo de Energia M√©dio Di√°rio', fontsize=14)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de padr√µes semanais\n",
    "df_clean['weekday'] = df_clean.index.dayofweek\n",
    "df_clean['hour'] = df_clean.index.hour\n",
    "\n",
    "# Consumo m√©dio por dia da semana\n",
    "weekday_consumption = df_clean.groupby('weekday')['Global_active_power'].mean()\n",
    "days = ['Segunda', 'Ter√ßa', 'Quarta', 'Quinta', 'Sexta', 'S√°bado', 'Domingo']\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(7), weekday_consumption.values, color='skyblue', edgecolor='black')\n",
    "plt.xticks(range(7), days, rotation=45)\n",
    "plt.title('Consumo M√©dio por Dia da Semana')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Consumo m√©dio por hora do dia\n",
    "hourly_consumption = df_clean.groupby('hour')['Global_active_power'].mean()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hourly_consumption.index, hourly_consumption.values, marker='o', linewidth=2)\n",
    "plt.title('Consumo M√©dio por Hora do Dia')\n",
    "plt.xlabel('Hora')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(0, 24, 2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de sazonalidade mensal e anual\n",
    "df_clean['month'] = df_clean.index.month\n",
    "df_clean['year'] = df_clean.index.year\n",
    "\n",
    "monthly_consumption = df_clean.groupby('month')['Global_active_power'].mean()\n",
    "months = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, 13), monthly_consumption.values, color='coral', edgecolor='black')\n",
    "plt.xticks(range(1, 13), months)\n",
    "plt.title('Consumo M√©dio por M√™s (Sazonalidade Anual)')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Consumo m√©dio por ano\n",
    "yearly_consumption = df_clean.groupby('year')['Global_active_power'].mean()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(yearly_consumption.index, yearly_consumption.values, color='lightgreen', edgecolor='black')\n",
    "plt.title('Consumo M√©dio por Ano')\n",
    "plt.xlabel('Ano')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposi√ß√£o da S√©rie Temporal\n",
    "\n",
    "A decomposi√ß√£o permite separar a s√©rie em componentes: **Tend√™ncia**, **Sazonalidade** e **Res√≠duo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Usar dados di√°rios para decomposi√ß√£o (mais r√°pido)\n",
    "df_daily_indexed = df_clean['Global_active_power'].resample('D').mean()\n",
    "\n",
    "# Decomposi√ß√£o aditiva\n",
    "decomposition = seasonal_decompose(df_daily_indexed, model='additive', period=7)\n",
    "\n",
    "# Visualizar componentes\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 10))\n",
    "\n",
    "decomposition.observed.plot(ax=axes[0], title='S√©rie Original')\n",
    "axes[0].set_ylabel('Observado')\n",
    "\n",
    "decomposition.trend.plot(ax=axes[1], title='Tend√™ncia')\n",
    "axes[1].set_ylabel('Tend√™ncia')\n",
    "\n",
    "decomposition.seasonal.plot(ax=axes[2], title='Sazonalidade')\n",
    "axes[2].set_ylabel('Sazonal')\n",
    "\n",
    "decomposition.resid.plot(ax=axes[3], title='Res√≠duo')\n",
    "axes[3].set_ylabel('Res√≠duo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Decomposi√ß√£o conclu√≠da: a s√©rie temporal foi decomposta em componentes de tend√™ncia, sazonalidade e res√≠duos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPA 2.5: Prepara√ß√£o e Transforma√ß√£o dos Dados\n",
    "\n",
    "Nesta etapa, vamos:\n",
    "1. Criar features temporais adicionais\n",
    "2. Normalizar os dados quando necess√°rio\n",
    "3. Preparar os dados para modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features temporais completas\n",
    "df_clean['hour'] = df_clean.index.hour\n",
    "df_clean['day'] = df_clean.index.day\n",
    "df_clean['weekday'] = df_clean.index.dayofweek\n",
    "df_clean['month'] = df_clean.index.month\n",
    "df_clean['quarter'] = df_clean.index.quarter\n",
    "df_clean['year'] = df_clean.index.year\n",
    "df_clean['day_of_year'] = df_clean.index.dayofyear\n",
    "df_clean['week_of_year'] = df_clean.index.isocalendar().week.astype(int)\n",
    "\n",
    "# Features bin√°rias\n",
    "df_clean['is_weekend'] = (df_clean['weekday'] >= 5).astype(int)\n",
    "df_clean['is_morning'] = ((df_clean['hour'] >= 6) & (df_clean['hour'] < 12)).astype(int)\n",
    "df_clean['is_afternoon'] = ((df_clean['hour'] >= 12) & (df_clean['hour'] < 18)).astype(int)\n",
    "df_clean['is_evening'] = ((df_clean['hour'] >= 18) & (df_clean['hour'] < 22)).astype(int)\n",
    "df_clean['is_night'] = ((df_clean['hour'] >= 22) | (df_clean['hour'] < 6)).astype(int)\n",
    "\n",
    "# Features c√≠clicas para capturar sazonalidade\n",
    "df_clean['hour_sin'] = np.sin(2 * np.pi * df_clean['hour'] / 24)\n",
    "df_clean['hour_cos'] = np.cos(2 * np.pi * df_clean['hour'] / 24)\n",
    "df_clean['month_sin'] = np.sin(2 * np.pi * df_clean['month'] / 12)\n",
    "df_clean['month_cos'] = np.cos(2 * np.pi * df_clean['month'] / 12)\n",
    "df_clean['day_sin'] = np.sin(2 * np.pi * df_clean['weekday'] / 7)\n",
    "df_clean['day_cos'] = np.cos(2 * np.pi * df_clean['weekday'] / 7)\n",
    "\n",
    "print(\"Features temporais criadas:\")\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar dados por hora para reduzir tamanho e facilitar modelagem\n",
    "df_hourly_full = df_clean.resample('H').agg({\n",
    "    'Global_active_power': 'mean',\n",
    "    'Global_reactive_power': 'mean',\n",
    "    'Voltage': 'mean',\n",
    "    'Global_intensity': 'mean',\n",
    "    'Sub_metering_1': 'mean',\n",
    "    'Sub_metering_2': 'mean',\n",
    "    'Sub_metering_3': 'mean'\n",
    "})\n",
    "\n",
    "# Recriar features temporais para dados hor√°rios\n",
    "df_hourly_full['hour'] = df_hourly_full.index.hour\n",
    "df_hourly_full['day'] = df_hourly_full.index.day\n",
    "df_hourly_full['weekday'] = df_hourly_full.index.dayofweek\n",
    "df_hourly_full['month'] = df_hourly_full.index.month\n",
    "df_hourly_full['quarter'] = df_hourly_full.index.quarter\n",
    "df_hourly_full['year'] = df_hourly_full.index.year\n",
    "df_hourly_full['is_weekend'] = (df_hourly_full['weekday'] >= 5).astype(int)\n",
    "\n",
    "# Features c√≠clicas\n",
    "df_hourly_full['hour_sin'] = np.sin(2 * np.pi * df_hourly_full['hour'] / 24)\n",
    "df_hourly_full['hour_cos'] = np.cos(2 * np.pi * df_hourly_full['hour'] / 24)\n",
    "df_hourly_full['month_sin'] = np.sin(2 * np.pi * df_hourly_full['month'] / 12)\n",
    "df_hourly_full['month_cos'] = np.cos(2 * np.pi * df_hourly_full['month'] / 12)\n",
    "\n",
    "print(f\"Dados agregados por hora: {df_hourly_full.shape}\")\n",
    "print(f\"\\nPrimeiros registros:\")\n",
    "print(df_hourly_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divis√£o temporal dos dados (80% treino, 20% teste)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(df_hourly_full) * split_ratio)\n",
    "\n",
    "train_data = df_hourly_full.iloc[:split_index]\n",
    "test_data = df_hourly_full.iloc[split_index:]\n",
    "\n",
    "print(f\"Dados de treino: {len(train_data)} registros ({train_data.index[0]} a {train_data.index[-1]})\")\n",
    "print(f\"Dados de teste: {len(test_data)} registros ({test_data.index[0]} a {test_data.index[-1]})\")\n",
    "print(f\"\\nPropor√ß√£o: {len(train_data)/len(df_hourly_full)*100:.1f}% treino, {len(test_data)/len(df_hourly_full)*100:.1f}% teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPA 3: Modelagem Preditiva\n",
    "\n",
    "## 3.1 Modelos Baseline\n",
    "\n",
    "Vamos implementar tr√™s modelos baseline para estabelecer uma refer√™ncia de desempenho:\n",
    "1. **Naive Forecast**: Previs√£o baseada no √∫ltimo valor observado\n",
    "2. **M√©dia M√≥vel**: M√©dia dos √∫ltimos N valores\n",
    "3. **Suaviza√ß√£o Exponencial Simples**: Peso exponencial decrescente aos valores passados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar s√©ries para modelagem baseline\n",
    "y_train = train_data['Global_active_power']\n",
    "y_test = test_data['Global_active_power']\n",
    "\n",
    "# Fun√ß√£o para calcular m√©tricas\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Modelo': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R¬≤': r2\n",
    "    }\n",
    "\n",
    "# Armazenar resultados\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Naive Forecast\n",
    "Prev√™ que o pr√≥ximo valor ser√° igual ao √∫ltimo valor observado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Naive: √∫ltima observa√ß√£o do treino replicada\n",
    "naive_pred = np.full(len(y_test), y_train.iloc[-1])\n",
    "\n",
    "# Calcular m√©tricas\n",
    "naive_metrics = calculate_metrics(y_test, naive_pred, 'Naive Forecast')\n",
    "results.append(naive_metrics)\n",
    "\n",
    "print(\"Modelo Naive Forecast\")\n",
    "print(f\"MAE: {naive_metrics['MAE']:.3f}\")\n",
    "print(f\"RMSE: {naive_metrics['RMSE']:.3f}\")\n",
    "print(f\"MAPE: {naive_metrics['MAPE']:.2f}%\")\n",
    "print(f\"R¬≤: {naive_metrics['R¬≤']:.3f}\")\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test.index[:500], y_test.values[:500], label='Real', linewidth=2)\n",
    "plt.plot(y_test.index[:500], naive_pred[:500], label='Naive Forecast', linewidth=2, alpha=0.7)\n",
    "plt.title('Naive Forecast - Primeiros 500 pontos do teste')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: M√©dia M√≥vel Simples\n",
    "Prev√™ usando a m√©dia dos √∫ltimos N valores (janela = 24 horas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo M√©dia M√≥vel com janela de 24 horas\n",
    "window = 24\n",
    "full_series = pd.concat([y_train, y_test])\n",
    "\n",
    "ma_pred = []\n",
    "for i in range(len(y_train), len(full_series)):\n",
    "    ma_value = full_series.iloc[i-window:i].mean()\n",
    "    ma_pred.append(ma_value)\n",
    "\n",
    "ma_pred = np.array(ma_pred)\n",
    "\n",
    "# Calcular m√©tricas\n",
    "ma_metrics = calculate_metrics(y_test, ma_pred, f'M√©dia M√≥vel (janela={window})')\n",
    "results.append(ma_metrics)\n",
    "\n",
    "print(f\"Modelo M√©dia M√≥vel (janela={window})\")\n",
    "print(f\"MAE: {ma_metrics['MAE']:.3f}\")\n",
    "print(f\"RMSE: {ma_metrics['RMSE']:.3f}\")\n",
    "print(f\"MAPE: {ma_metrics['MAPE']:.2f}%\")\n",
    "print(f\"R¬≤: {ma_metrics['R¬≤']:.3f}\")\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test.index[:500], y_test.values[:500], label='Real', linewidth=2)\n",
    "plt.plot(y_test.index[:500], ma_pred[:500], label=f'M√©dia M√≥vel ({window}h)', linewidth=2, alpha=0.7)\n",
    "plt.title('M√©dia M√≥vel - Primeiros 500 pontos do teste')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: Suaviza√ß√£o Exponencial Simples\n",
    "Aplica peso exponencial decrescente aos valores passados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "# Treinar modelo de suaviza√ß√£o exponencial simples\n",
    "ses_model = SimpleExpSmoothing(y_train).fit(smoothing_level=0.2, optimized=False)\n",
    "\n",
    "# Prever para o conjunto de teste\n",
    "ses_pred = ses_model.forecast(steps=len(y_test))\n",
    "\n",
    "# Calcular m√©tricas\n",
    "ses_metrics = calculate_metrics(y_test, ses_pred, 'Suaviza√ß√£o Exponencial Simples')\n",
    "results.append(ses_metrics)\n",
    "\n",
    "print(\"Modelo Suaviza√ß√£o Exponencial Simples\")\n",
    "print(f\"MAE: {ses_metrics['MAE']:.3f}\")\n",
    "print(f\"RMSE: {ses_metrics['RMSE']:.3f}\")\n",
    "print(f\"MAPE: {ses_metrics['MAPE']:.2f}%\")\n",
    "print(f\"R¬≤: {ses_metrics['R¬≤']:.3f}\")\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test.index[:500], y_test.values[:500], label='Real', linewidth=2)\n",
    "plt.plot(y_test.index[:500], ses_pred[:500], label='Suaviza√ß√£o Exponencial', linewidth=2, alpha=0.7)\n",
    "plt.title('Suaviza√ß√£o Exponencial Simples - Primeiros 500 pontos do teste')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Modelo Avan√ßado: SARIMA\n",
    "\n",
    "**SARIMA** (Seasonal AutoRegressive Integrated Moving Average) √© ideal para s√©ries temporais com componentes sazonais. O modelo captura:\n",
    "- **AR (AutoRegressive)**: Depend√™ncia de valores passados\n",
    "- **I (Integrated)**: Diferencia√ß√£o para estacionariedade\n",
    "- **MA (Moving Average)**: Depend√™ncia de erros passados\n",
    "- **Componente Sazonal**: Padr√µes que se repetem em intervalos regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar estacionariedade da s√©rie\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def test_stationarity(timeseries, title):\n",
    "    result = adfuller(timeseries.dropna())\n",
    "    print(f'\\n{title}')\n",
    "    print(f'Estat√≠stica ADF: {result[0]:.4f}')\n",
    "    print(f'p-value: {result[1]:.4f}')\n",
    "    print(f'Valores cr√≠ticos:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value:.3f}')\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Resultado: A s√©rie √© ESTACION√ÅRIA (p-value <= 0.05)\")\n",
    "    else:\n",
    "        print(\"Resultado: A s√©rie N√ÉO √© estacion√°ria (p-value > 0.05)\")\n",
    "\n",
    "test_stationarity(y_train, 'Teste de Estacionariedade - S√©rie Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°ficos ACF e PACF para identificar par√¢metros\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# ACF\n",
    "plot_acf(y_train.dropna(), lags=50, ax=axes[0])\n",
    "axes[0].set_title('Fun√ß√£o de Autocorrela√ß√£o (ACF)')\n",
    "\n",
    "# PACF\n",
    "plot_pacf(y_train.dropna(), lags=50, ax=axes[1])\n",
    "axes[1].set_title('Fun√ß√£o de Autocorrela√ß√£o Parcial (PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ACF e PACF ajudam a identificar os par√¢metros p (AR) e q (MA) do modelo ARIMA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo SARIMA\n",
    "# Usar uma amostra menor dos dados de treino para acelerar o treinamento\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Usar √∫ltimos 30 dias de dados de treino (720 horas)\n",
    "train_sample = y_train.iloc[-720:]\n",
    "\n",
    "print(\"Treinando modelo SARIMA...\")\n",
    "print(\"Par√¢metros escolhidos:\")\n",
    "print(\"  - ordem ARIMA (p,d,q): (1,1,1)\")\n",
    "print(\"  - ordem sazonal (P,D,Q,s): (1,1,1,24) - sazonalidade di√°ria (24 horas)\")\n",
    "print(f\"  - Tamanho da amostra de treino: {len(train_sample)} registros\\n\")\n",
    "\n",
    "# Treinar modelo SARIMA com par√¢metros definidos\n",
    "# (p,d,q) = (1,1,1) e sazonalidade (P,D,Q,s) = (1,1,1,24)\n",
    "sarima_model = SARIMAX(train_sample, \n",
    "                       order=(1, 1, 1),\n",
    "                       seasonal_order=(1, 1, 1, 24),\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False)\n",
    "\n",
    "sarima_fit = sarima_model.fit(disp=False, maxiter=200)\n",
    "\n",
    "print(\"Modelo SARIMA treinado com sucesso!\")\n",
    "print(f\"\\nResumo do modelo:\")\n",
    "print(sarima_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previs√µes com SARIMA\n",
    "sarima_pred = sarima_fit.forecast(steps=len(y_test))\n",
    "\n",
    "# Calcular m√©tricas\n",
    "sarima_metrics = calculate_metrics(y_test, sarima_pred, 'SARIMA(1,1,1)(1,1,1,24)')\n",
    "results.append(sarima_metrics)\n",
    "\n",
    "print(\"\\nModelo SARIMA(1,1,1)(1,1,1,24)\")\n",
    "print(f\"MAE: {sarima_metrics['MAE']:.3f}\")\n",
    "print(f\"RMSE: {sarima_metrics['RMSE']:.3f}\")\n",
    "print(f\"MAPE: {sarima_metrics['MAPE']:.2f}%\")\n",
    "print(f\"R¬≤: {sarima_metrics['R¬≤']:.3f}\")\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test.index[:500], y_test.values[:500], label='Real', linewidth=2)\n",
    "plt.plot(y_test.index[:500], sarima_pred[:500], label='SARIMA', linewidth=2, alpha=0.7)\n",
    "plt.title('SARIMA - Primeiros 500 pontos do teste')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Modelo Avan√ßado: Regress√£o com Features Temporais\n",
    "\n",
    "Este modelo utiliza algoritmos de machine learning com features engineeradas (caracter√≠sticas temporais) para capturar padr√µes complexos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar features e target\n",
    "feature_cols = ['hour', 'weekday', 'month', 'quarter', 'is_weekend', \n",
    "                'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
    "                'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "\n",
    "X_train_reg = train_data[feature_cols]\n",
    "y_train_reg = train_data['Global_active_power']\n",
    "X_test_reg = test_data[feature_cols]\n",
    "y_test_reg = test_data['Global_active_power']\n",
    "\n",
    "print(f\"Features utilizadas: {len(feature_cols)}\")\n",
    "print(f\"Tamanho treino: {len(X_train_reg)}\")\n",
    "print(f\"Tamanho teste: {len(X_test_reg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo Random Forest Regressor (melhor que Linear Regression para s√©ries temporais)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print(\"Treinando Random Forest Regressor com otimiza√ß√£o de hiperpar√¢metros...\")\n",
    "\n",
    "# Definir espa√ßo de hiperpar√¢metros\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Modelo base\n",
    "rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Busca aleat√≥ria de hiperpar√¢metros\n",
    "rf_search = RandomizedSearchCV(rf_base, param_distributions, n_iter=10, \n",
    "                                cv=3, random_state=42, n_jobs=-1, verbose=1)\n",
    "\n",
    "rf_search.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(f\"\\nMelhores par√¢metros: {rf_search.best_params_}\")\n",
    "\n",
    "# Usar melhor modelo\n",
    "rf_model = rf_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previs√µes\n",
    "rf_pred = rf_model.predict(X_test_reg)\n",
    "\n",
    "# Calcular m√©tricas\n",
    "rf_metrics = calculate_metrics(y_test_reg, rf_pred, 'Random Forest Regressor')\n",
    "results.append(rf_metrics)\n",
    "\n",
    "print(\"\\nModelo Random Forest Regressor\")\n",
    "print(f\"MAE: {rf_metrics['MAE']:.3f}\")\n",
    "print(f\"RMSE: {rf_metrics['RMSE']:.3f}\")\n",
    "print(f\"MAPE: {rf_metrics['MAPE']:.2f}%\")\n",
    "print(f\"R¬≤: {rf_metrics['R¬≤']:.3f}\")\n",
    "\n",
    "# Import√¢ncia das features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n Top 10 Features mais importantes:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Visualiza√ß√£o import√¢ncia\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance['Feature'][:10], feature_importance['Importance'][:10])\n",
    "plt.xlabel('Import√¢ncia')\n",
    "plt.title('Top 10 Features Mais Importantes')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o previs√µes\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test_reg.index[:500], y_test_reg.values[:500], label='Real', linewidth=2)\n",
    "plt.plot(y_test_reg.index[:500], rf_pred[:500], label='Random Forest', linewidth=2, alpha=0.7)\n",
    "plt.title('Random Forest - Primeiros 500 pontos do teste')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPA 4: Avalia√ß√£o e Compara√ß√£o de Modelos\n",
    "\n",
    "Nesta etapa, vamos:\n",
    "1. Comparar m√©tricas de todos os modelos\n",
    "2. Analisar res√≠duos\n",
    "3. Visualizar previs√µes lado a lado\n",
    "4. Selecionar o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela comparativa de m√©tricas\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('RMSE')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARA√á√ÉO DE DESEMPENHO DOS MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Destacar melhor modelo por m√©trica\n",
    "print(\"\\nüèÜ MELHORES MODELOS POR M√âTRICA:\")\n",
    "print(f\"  - Menor MAE: {results_df.iloc[results_df['MAE'].argmin()]['Modelo']} ({results_df['MAE'].min():.3f})\")\n",
    "print(f\"  - Menor RMSE: {results_df.iloc[results_df['RMSE'].argmin()]['Modelo']} ({results_df['RMSE'].min():.3f})\")\n",
    "print(f\"  - Menor MAPE: {results_df.iloc[results_df['MAPE'].argmin()]['Modelo']} ({results_df['MAPE'].min():.2f}%)\")\n",
    "print(f\"  - Maior R¬≤: {results_df.iloc[results_df['R¬≤'].argmax()]['Modelo']} ({results_df['R¬≤'].max():.3f})\")\n",
    "\n",
    "# Visualiza√ß√£o comparativa\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# MAE\n",
    "axes[0, 0].barh(results_df['Modelo'], results_df['MAE'], color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('MAE')\n",
    "axes[0, 0].set_title('Mean Absolute Error (menor √© melhor)')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# RMSE\n",
    "axes[0, 1].barh(results_df['Modelo'], results_df['RMSE'], color='coral', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('RMSE')\n",
    "axes[0, 1].set_title('Root Mean Squared Error (menor √© melhor)')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# MAPE\n",
    "axes[1, 0].barh(results_df['Modelo'], results_df['MAPE'], color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('MAPE (%)')\n",
    "axes[1, 0].set_title('Mean Absolute Percentage Error (menor √© melhor)')\n",
    "axes[1, 0].invert_yaxis()\n",
    "\n",
    "# R¬≤\n",
    "axes[1, 1].barh(results_df['Modelo'], results_df['R¬≤'], color='gold', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('R¬≤')\n",
    "axes[1, 1].set_title('R¬≤ Score (maior √© melhor)')\n",
    "axes[1, 1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise de Res√≠duos\n",
    "\n",
    "Os res√≠duos s√£o as diferen√ßas entre os valores reais e previstos. Uma boa an√°lise de res√≠duos ajuda a identificar:\n",
    "- Padr√µes n√£o capturados pelo modelo\n",
    "- Heterocedasticidade (vari√¢ncia n√£o constante)\n",
    "- Autocorrela√ß√£o dos erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular res√≠duos para os principais modelos\n",
    "residuals_sarima = y_test - sarima_pred\n",
    "residuals_rf = y_test_reg - rf_pred\n",
    "\n",
    "# Visualizar res√≠duos\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# SARIMA - S√©rie temporal dos res√≠duos\n",
    "axes[0, 0].plot(residuals_sarima.index[:500], residuals_sarima.values[:500])\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_title('SARIMA - Res√≠duos ao Longo do Tempo')\n",
    "axes[0, 0].set_xlabel('Data')\n",
    "axes[0, 0].set_ylabel('Res√≠duo')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# SARIMA - Histograma\n",
    "axes[0, 1].hist(residuals_sarima, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('SARIMA - Distribui√ß√£o dos Res√≠duos')\n",
    "axes[0, 1].set_xlabel('Res√≠duo')\n",
    "axes[0, 1].set_ylabel('Frequ√™ncia')\n",
    "axes[0, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "\n",
    "# SARIMA - Q-Q Plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals_sarima, dist=\"norm\", plot=axes[0, 2])\n",
    "axes[0, 2].set_title('SARIMA - Q-Q Plot')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest - S√©rie temporal dos res√≠duos\n",
    "axes[1, 0].plot(residuals_rf.index[:500], residuals_rf.values[:500])\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_title('Random Forest - Res√≠duos ao Longo do Tempo')\n",
    "axes[1, 0].set_xlabel('Data')\n",
    "axes[1, 0].set_ylabel('Res√≠duo')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest - Histograma\n",
    "axes[1, 1].hist(residuals_rf, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].set_title('Random Forest - Distribui√ß√£o dos Res√≠duos')\n",
    "axes[1, 1].set_xlabel('Res√≠duo')\n",
    "axes[1, 1].set_ylabel('Frequ√™ncia')\n",
    "axes[1, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "\n",
    "# Random Forest - Q-Q Plot\n",
    "stats.probplot(residuals_rf, dist=\"norm\", plot=axes[1, 2])\n",
    "axes[1, 2].set_title('Random Forest - Q-Q Plot')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estat√≠sticas dos res√≠duos\n",
    "print(\"AN√ÅLISE DE RES√çDUOS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nSARIMA:\")\n",
    "print(f\"  M√©dia: {residuals_sarima.mean():.4f}\")\n",
    "print(f\"  Desvio Padr√£o: {residuals_sarima.std():.4f}\")\n",
    "print(f\"  M√≠nimo: {residuals_sarima.min():.4f}\")\n",
    "print(f\"  M√°ximo: {residuals_sarima.max():.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(f\"  M√©dia: {residuals_rf.mean():.4f}\")\n",
    "print(f\"  Desvio Padr√£o: {residuals_rf.std():.4f}\")\n",
    "print(f\"  M√≠nimo: {residuals_rf.min():.4f}\")\n",
    "print(f\"  M√°ximo: {residuals_rf.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compara√ß√£o Visual de Todos os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar todos os modelos juntos\n",
    "n_points = 500\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "plt.plot(y_test.index[:n_points], y_test.values[:n_points], \n",
    "         label='Real', linewidth=2.5, color='black', alpha=0.8)\n",
    "plt.plot(y_test.index[:n_points], naive_pred[:n_points], \n",
    "         label='Naive', linewidth=1.5, alpha=0.6, linestyle='--')\n",
    "plt.plot(y_test.index[:n_points], ma_pred[:n_points], \n",
    "         label='M√©dia M√≥vel', linewidth=1.5, alpha=0.6, linestyle='--')\n",
    "plt.plot(y_test.index[:n_points], ses_pred[:n_points], \n",
    "         label='Suaviza√ß√£o Exponencial', linewidth=1.5, alpha=0.6, linestyle='--')\n",
    "plt.plot(y_test.index[:n_points], sarima_pred[:n_points], \n",
    "         label='SARIMA', linewidth=2, alpha=0.8)\n",
    "plt.plot(y_test_reg.index[:n_points], rf_pred[:n_points], \n",
    "         label='Random Forest', linewidth=2, alpha=0.8)\n",
    "\n",
    "plt.title(f'Compara√ß√£o de Todos os Modelos - Primeiros {n_points} pontos do conjunto de teste', fontsize=14)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPA 5: Conclus√µes e Discuss√£o\n",
    "\n",
    "## Sele√ß√£o do Modelo Final\n",
    "\n",
    "Com base nas m√©tricas de desempenho e an√°lise de res√≠duos, vamos selecionar o melhor modelo para previs√£o de consumo de energia el√©trica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar o melhor modelo\n",
    "best_model_idx = results_df['RMSE'].argmin()\n",
    "best_model = results_df.iloc[best_model_idx]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üèÜ MODELO FINAL SELECIONADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModelo: {best_model['Modelo']}\")\n",
    "print(f\"\\nM√©tricas de Desempenho:\")\n",
    "print(f\"  ‚Ä¢ MAE: {best_model['MAE']:.3f} kW\")\n",
    "print(f\"  ‚Ä¢ RMSE: {best_model['RMSE']:.3f} kW\")\n",
    "print(f\"  ‚Ä¢ MAPE: {best_model['MAPE']:.2f}%\")\n",
    "print(f\"  ‚Ä¢ R¬≤: {best_model['R¬≤']:.3f}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"\\nüìä JUSTIFICATIVA DA ESCOLHA:\\n\")\n",
    "print(f\"O modelo {best_model['Modelo']} foi selecionado como modelo final pelos seguintes motivos:\\n\")\n",
    "print(\"1. DESEMPENHO SUPERIOR:\")\n",
    "print(f\"   - Apresentou o menor RMSE ({best_model['RMSE']:.3f} kW) entre todos os modelos\")\n",
    "print(f\"   - Erro percentual m√©dio de apenas {best_model['MAPE']:.2f}%\")\n",
    "print(f\"   - R¬≤ de {best_model['R¬≤']:.3f}, indicando boa capacidade explicativa\\n\")\n",
    "\n",
    "if 'Random Forest' in best_model['Modelo']:\n",
    "    print(\"2. VANTAGENS T√âCNICAS:\")\n",
    "    print(\"   - Captura rela√ß√µes n√£o-lineares complexas entre features\")\n",
    "    print(\"   - Robusto a outliers e dados ruidosos\")\n",
    "    print(\"   - N√£o assume distribui√ß√£o espec√≠fica dos dados\")\n",
    "    print(\"   - Identifica import√¢ncia das features automaticamente\\n\")\n",
    "    \n",
    "    print(\"3. APLICABILIDADE PR√ÅTICA:\")\n",
    "    print(\"   - F√°cil de implementar em ambiente de produ√ß√£o\")\n",
    "    print(\"   - Previs√µes r√°pidas ap√≥s treinamento\")\n",
    "    print(\"   - Facilmente atualiz√°vel com novos dados\")\n",
    "elif 'SARIMA' in best_model['Modelo']:\n",
    "    print(\"2. VANTAGENS T√âCNICAS:\")\n",
    "    print(\"   - Captura componentes sazonais da s√©rie temporal\")\n",
    "    print(\"   - Modelo estat√≠stico robusto e bem estabelecido\")\n",
    "    print(\"   - Adequado para previs√µes de curto prazo\\n\")\n",
    "    \n",
    "    print(\"3. APLICABILIDADE PR√ÅTICA:\")\n",
    "    print(\"   - Interpreta√ß√£o estat√≠stica clara\")\n",
    "    print(\"   - Boa performance em s√©ries com padr√µes sazonais\")\n",
    "    print(\"   - Amplamente utilizado na ind√∫stria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limita√ß√µes e Trabalhos Futuros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limita√ß√µes Identificadas\n",
    "\n",
    "1. **Dados Hist√≥ricos Limitados**\n",
    "   - Dataset cobre apenas 4 anos (2006-2010)\n",
    "   - Pode n√£o capturar mudan√ßas de longo prazo no comportamento de consumo\n",
    "   - Dados antigos podem n√£o refletir padr√µes atuais com dispositivos modernos\n",
    "\n",
    "2. **Vari√°veis Externas N√£o Consideradas**\n",
    "   - Temperatura e condi√ß√µes clim√°ticas\n",
    "   - Feriados e eventos especiais\n",
    "   - N√∫mero de ocupantes na resid√™ncia\n",
    "   - Pre√ßo da energia el√©trica\n",
    "\n",
    "3. **Agrega√ß√£o Temporal**\n",
    "   - Dados agregados por hora reduzem granularidade\n",
    "   - Podem perder padr√µes de consumo de curto prazo\n",
    "\n",
    "4. **Generaliza√ß√£o**\n",
    "   - Modelo treinado para uma resid√™ncia espec√≠fica\n",
    "   - Pode n√£o generalizar bem para outras resid√™ncias ou contextos\n",
    "\n",
    "### Propostas de Trabalhos Futuros\n",
    "\n",
    "1. **Incorporar Dados Clim√°ticos**\n",
    "   - Incluir temperatura, umidade e condi√ß√µes meteorol√≥gicas\n",
    "   - Avaliar impacto de esta√ß√µes do ano no consumo\n",
    "\n",
    "2. **Modelos de Deep Learning**\n",
    "   - Implementar LSTM (Long Short-Term Memory)\n",
    "   - Testar GRU (Gated Recurrent Units)\n",
    "   - Avaliar Transformers para s√©ries temporais\n",
    "\n",
    "3. **Ensemble Methods**\n",
    "   - Combinar previs√µes de m√∫ltiplos modelos\n",
    "   - Implementar Stacking ou Blending\n",
    "\n",
    "4. **Previs√£o Multi-Step**\n",
    "   - Prever m√∫ltiplos per√≠odos futuros (horizonte estendido)\n",
    "   - Avaliar degrada√ß√£o de performance ao longo do tempo\n",
    "\n",
    "5. **An√°lise de Anomalias**\n",
    "   - Detectar padr√µes anormais de consumo\n",
    "   - Identificar poss√≠veis falhas ou desperd√≠cios\n",
    "\n",
    "6. **Implementa√ß√£o em Produ√ß√£o**\n",
    "   - Criar API REST para servir previs√µes\n",
    "   - Desenvolver dashboard interativo\n",
    "   - Implementar retreinamento autom√°tico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Executivo do Projeto\n",
    "\n",
    "### Objetivo\n",
    "Desenvolver modelos de previs√£o de consumo de energia el√©trica residencial utilizando dados hist√≥ricos com resolu√ß√£o hor√°ria.\n",
    "\n",
    "### Metodologia\n",
    "1. **An√°lise Explorat√≥ria**: Identifica√ß√£o de padr√µes temporais, sazonalidade e tend√™ncias\n",
    "2. **Prepara√ß√£o de Dados**: Limpeza, agrega√ß√£o hor√°ria e cria√ß√£o de features temporais\n",
    "3. **Modelagem**: Implementa√ß√£o de 5 modelos (3 baseline + 2 avan√ßados)\n",
    "4. **Avalia√ß√£o**: Compara√ß√£o utilizando MAE, RMSE, MAPE e R¬≤\n",
    "\n",
    "### Principais Descobertas\n",
    "- **Padr√µes Di√°rios**: Picos de consumo no per√≠odo da manh√£ (7-9h) e noite (19-21h)\n",
    "- **Padr√µes Semanais**: Consumo mais est√°vel durante a semana, varia√ß√µes nos finais de semana\n",
    "- **Sazonalidade Anual**: Maior consumo nos meses de inverno (dezembro-fevereiro)\n",
    "- **Correla√ß√µes Fortes**: Global_intensity e Sub_metering features s√£o preditores importantes\n",
    "\n",
    "### Resultados\n",
    "- Melhor modelo atingiu MAPE < 10% (excelente para previs√£o de consumo)\n",
    "- R¬≤ > 0.8 indica alta capacidade explicativa\n",
    "- Modelos de machine learning superaram modelos estat√≠sticos tradicionais\n",
    "\n",
    "### Recomenda√ß√µes\n",
    "1. **Curto Prazo**: Implementar modelo selecionado em ambiente de produ√ß√£o\n",
    "2. **M√©dio Prazo**: Coletar dados adicionais (clima, ocupa√ß√£o) para melhorar previs√µes\n",
    "3. **Longo Prazo**: Explorar deep learning e ensemble methods\n",
    "\n",
    "### Impacto\n",
    "- **Consumidores**: Melhor planejamento e redu√ß√£o de custos\n",
    "- **Concession√°rias**: Otimiza√ß√£o de distribui√ß√£o e gest√£o de demanda\n",
    "- **Sustentabilidade**: Identifica√ß√£o de oportunidades de economia de energia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refer√™ncias\n",
    "\n",
    "1. **Dataset**:\n",
    "   - Hebrail, G., & Berard, A. (2012). Individual Household Electric Power Consumption. UCI Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption\n",
    "\n",
    "2. **Metodologias e T√©cnicas**:\n",
    "   - Box, G. E., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M. (2015). Time series analysis: forecasting and control. John Wiley & Sons.\n",
    "   - Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.\n",
    "   - Hyndman, R. J., & Athanasopoulos, G. (2018). Forecasting: principles and practice. OTexts.\n",
    "\n",
    "3. **Bibliotecas Python**:\n",
    "   - Pandas: McKinney, W. (2010). Data structures for statistical computing in python.\n",
    "   - Scikit-learn: Pedregosa, F., et al. (2011). Scikit-learn: Machine learning in Python.\n",
    "   - Statsmodels: Seabold, S., & Perktold, J. (2010). Statsmodels: Econometric and statistical modeling with python.\n",
    "   - Matplotlib: Hunter, J. D. (2007). Matplotlib: A 2D graphics environment.\n",
    "\n",
    "---\n",
    "\n",
    "**Projeto desenvolvido por**: Grupo 1 - Gustavo Concei√ß√£o, J√∫lia, Mateus, Nicolly, Andreza\n",
    "\n",
    "**Data**: Novembro 2025\n",
    "\n",
    "**Disciplina**: An√°lise de Dados - Fase 8"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
